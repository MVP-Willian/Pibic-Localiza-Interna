{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "028e075d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define a opção para mostrar TODAS as colunas, sem limite\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Define a opção para mostrar TODAS as linhas, sem limite\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "\n",
    "# Define a opção para mostrar o número máximo de elementos do array como infinito (None)\n",
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "ee34c550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2090, 20)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"../datasets/dataframe_yuri_xiaomi_x5.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "ee54aa54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of        B1   B2   B3   B4   B5   B6   B7   B8   B9\n",
      "0     -80  -78  -53  -76  -78  -77  -83  -78  -80\n",
      "1     -64  -73  -55  -72  -78  -76  -79  -78 -105\n",
      "2     -69  -68  -58  -70  -80  -80  -82  -71  -82\n",
      "3     -69  -65  -58  -70  -80  -77  -85  -72  -92\n",
      "4     -65  -67  -56  -69  -80  -77  -76  -71  -79\n",
      "5     -64  -67  -56  -70  -78  -76  -78  -73  -80\n",
      "6     -64  -75  -56  -74  -81  -78  -76  -82  -81\n",
      "7     -65  -76  -56  -70  -80  -78  -78  -89  -81\n",
      "8     -69  -68  -58  -69  -80  -78  -85  -73  -90\n",
      "9     -70  -68  -59  -71  -79  -79  -83  -72 -105\n",
      "10    -64  -68  -56  -70  -79  -77  -81  -72  -82\n",
      "11    -66  -68  -56  -71  -78  -78  -80  -77  -83\n",
      "12    -66  -76  -56  -74  -81  -78  -78  -74  -83\n",
      "13    -72  -73  -56  -75  -74  -74  -78  -75  -93\n",
      "14    -71  -73  -57  -73  -76  -76  -81  -74  -82\n",
      "15    -74  -72  -57  -76  -78  -74  -80  -74  -84\n",
      "66    -82  -80  -78  -70  -81  -74  -70  -72  -79\n",
      "67    -84  -86  -79  -69  -82  -73  -71  -72  -76\n",
      "68    -81  -77  -76  -70  -76  -71  -69  -69  -82\n",
      "69    -75  -77  -74  -67  -71  -80  -70  -71  -76\n",
      "70    -83  -84  -76  -68  -74  -78  -67  -76  -84\n",
      "71    -80  -80  -77  -68  -81  -74  -66  -69  -73\n",
      "72    -75  -79 -105  -67  -69  -69  -66  -66  -75\n",
      "73    -85  -76  -86  -70  -71  -72  -68  -75  -77\n",
      "74    -78  -78  -80  -68  -76  -74  -65  -70  -74\n",
      "75    -80  -78  -76  -69  -85  -72  -67  -71  -73\n",
      "76    -84  -79  -73  -77  -78  -76  -71  -70  -78\n",
      "77    -81  -76  -80  -76  -71  -70  -73  -73  -77\n",
      "78    -80  -74  -74  -69  -71  -66  -74  -77  -76\n",
      "79    -78  -81  -77  -62  -71  -68  -72  -78  -77\n",
      "80    -78  -77  -76  -63  -74  -68  -71  -76  -76\n",
      "81    -80 -105  -73  -62  -68  -69  -72  -70  -82\n",
      "132   -78  -81  -82  -84  -78  -80  -63  -63  -71\n",
      "133   -79  -83  -82  -78  -80  -66  -64  -56  -74\n",
      "134   -78  -91  -80  -81  -75  -76  -69  -63  -72\n",
      "135   -88  -94  -82  -80  -73  -80  -68  -75  -73\n",
      "136   -80  -86  -82  -82  -74  -69  -68  -66  -71\n",
      "137   -76  -83  -82  -78  -72  -70  -71  -65  -70\n",
      "138   -85  -84  -79  -82  -71  -72  -72  -59  -70\n",
      "139   -78 -105  -79  -78  -74  -66  -73  -57  -78\n",
      "140   -89  -93  -80  -83  -72  -74  -70  -59  -72\n",
      "141   -91  -85  -76  -82  -72  -78  -69  -63  -72\n",
      "142   -76  -82  -78  -83  -73  -76  -71  -56  -71\n",
      "143   -82  -83  -80  -79  -75  -68  -69  -57  -71\n",
      "144   -81  -82  -80  -80  -72  -78  -71  -60  -69\n",
      "145   -80  -86  -82  -82  -73  -66  -82  -58  -72\n",
      "146   -82 -105  -83  -86  -72  -80  -76  -58  -73\n",
      "147   -89 -105  -82  -84  -71  -78  -80  -60  -73\n",
      "199   -79  -78  -72  -60  -80  -76  -74  -72  -73\n",
      "200   -73  -80  -71  -66  -70  -77  -74  -70  -74\n",
      "201   -72  -81  -67  -62  -70  -80  -69  -74  -72\n",
      "202   -76  -81  -69  -66  -75  -79  -70  -80  -70\n",
      "203   -73  -80  -71  -62  -68 -105  -74  -70  -73\n",
      "204  -105  -78  -72  -69  -68  -80 -105  -69  -80\n",
      "205   -80  -84  -68  -69  -71  -79  -73  -63  -73\n",
      "206   -73 -105  -69  -63  -72  -75  -70  -66  -71\n",
      "207   -72  -78  -68  -63  -68  -75  -67  -80  -80\n",
      "208   -70 -105  -67  -68  -67  -70  -72  -72  -71\n",
      "209   -72  -82  -71  -69  -69  -73  -72  -66  -75\n",
      "210   -84  -84  -69  -72  -73  -82  -69  -66  -71\n",
      "211   -79  -86  -68  -72  -75  -73  -69  -62  -71\n",
      "212   -72  -84  -68  -71  -70  -73  -70  -66  -72\n",
      "213   -72  -84  -70  -71  -70  -72  -70  -67  -72\n",
      "214   -72  -83  -70  -71  -70  -72  -72  -66  -72\n",
      "265   -76  -89  -64  -62  -67 -105  -78  -68  -72\n",
      "266   -77  -76  -66  -66  -76  -76  -74  -74  -71\n",
      "267   -78  -79  -67  -69  -76  -78  -70  -66  -73\n",
      "268   -78  -81  -70  -65  -82  -76  -77  -64  -73\n",
      "269   -77  -73  -67  -61  -76  -76  -76  -67  -75\n",
      "270   -80  -87  -67  -67  -82  -80  -76  -68  -74\n",
      "271   -78  -74 -105  -66  -83  -83  -83 -105  -73\n",
      "272   -77  -77  -66  -63  -79  -80  -78  -76  -75\n",
      "273   -79  -80  -70  -66  -83  -81  -78  -75  -75\n",
      "274   -79  -81  -70  -66  -75  -80  -78  -74  -74\n",
      "275   -74  -80  -66  -67  -76  -76  -84  -66  -75\n",
      "276   -78  -80  -66  -70  -75  -81 -105  -67 -105\n",
      "277   -74  -73  -66  -72  -76  -74  -71  -73  -72\n",
      "278   -76  -71  -68  -67  -84  -81  -74  -69  -71\n",
      "279   -84  -80  -66  -72  -71  -80  -73  -60  -74\n",
      "280   -78  -77  -69  -68  -73  -79  -73  -70  -78\n",
      "281   -79  -77  -64  -60  -75  -74  -74  -74  -88\n",
      "331   -80  -74  -72  -79  -68  -78  -79  -72  -80\n",
      "332   -76  -73  -68  -78  -69  -80  -79  -74  -85\n",
      "333   -80  -74  -68  -78  -70  -82  -79  -74  -90\n",
      "334   -79  -76  -73  -75  -68  -77  -83  -69  -76\n",
      "335   -80  -72  -72  -77  -70  -74  -76  -72  -80\n",
      "336   -80  -72  -76  -75  -78  -77  -84  -78  -91\n",
      "337   -80  -73  -74  -77  -74  -81  -78  -76  -84\n",
      "338   -78  -76  -70  -81  -62  -76  -78  -69  -80\n",
      "339   -85  -76  -73  -70  -74  -72  -78  -71  -74\n",
      "340   -78  -88  -70  -88  -64  -79  -80  -80  -80\n",
      "341   -84  -76  -75  -70  -66  -71  -81  -73  -76\n",
      "342   -84  -76  -76  -72  -68  -70 -105  -77  -76\n",
      "343   -79  -76  -70  -73  -64  -73  -81  -70  -73\n",
      "344   -75  -76  -70  -76  -77  -76  -76  -75  -78\n",
      "345   -77  -74  -73  -72  -72  -80  -77  -70  -77\n",
      "346   -81  -78  -68  -74  -79  -74  -74  -80  -81\n",
      "396   -72  -96  -79  -72  -72  -65  -72  -68  -67\n",
      "397   -82  -84  -74  -71  -71  -71  -71  -72  -71\n",
      "398   -79  -83  -72  -74  -73  -74  -75 -105  -78\n",
      "399   -80  -92  -70  -73  -69  -73  -74  -64  -73\n",
      "400   -85  -89  -72  -72  -69  -75  -78  -62  -76\n",
      "401   -72  -89  -73  -71  -69  -76  -76  -62  -72\n",
      "402   -83  -87  -72  -74  -71  -80  -81  -67  -74\n",
      "403   -87  -84  -72  -71  -70  -75  -77  -67  -73\n",
      "404   -84  -86  -73  -72  -71  -74  -78  -68  -74\n",
      "405   -75  -86  -72  -75  -70  -76  -80  -67  -76\n",
      "406   -75  -84  -72  -77  -68  -77  -80  -68  -77\n",
      "407   -74  -85  -73  -72  -70  -75  -79  -69  -74\n",
      "408   -73  -87  -72  -72  -70  -73  -78  -68  -75\n",
      "409   -83  -84  -73  -74  -71  -75  -81  -68  -75\n",
      "410   -75  -82  -75  -76  -75  -72  -81  -67  -76\n",
      "411   -76  -75  -75  -80  -74  -68  -73  -77  -74\n",
      "462   -76  -76  -72  -70  -80  -80  -82  -80  -85\n",
      "463   -74 -105  -72  -69 -105  -75 -105  -70  -81\n",
      "464   -76  -71  -68  -69  -82  -77  -79  -74  -75\n",
      "465   -78  -71  -66  -66  -78  -77  -84  -78  -78\n",
      "466   -79  -72  -67  -71  -84  -75  -76  -72  -76\n",
      "467   -81  -75  -68  -67  -87  -74  -77  -76  -78\n",
      "468   -82  -73  -70  -67  -77  -96  -80  -73  -82\n",
      "469   -76  -73  -75  -71  -79  -75  -83  -68  -88\n",
      "470   -76  -70  -67  -68  -80  -77  -78  -76  -76\n",
      "471   -81  -72  -68  -65  -84 -105  -78  -78  -77\n",
      "472   -82  -76  -68  -65  -82  -83  -80  -80  -84\n",
      "473   -83  -75  -69  -67  -79  -78  -82  -78  -84\n",
      "474   -80  -74  -72  -69  -76  -85  -77  -74  -80\n",
      "475   -75  -81  -71  -73  -76  -80  -77  -70  -83\n",
      "476   -76  -77  -69  -69  -73  -74  -78  -69  -74\n",
      "477   -77  -76  -69  -71  -77  -75  -80  -70  -74\n",
      "478   -77  -76  -68  -69  -82  -75  -80  -74  -81\n",
      "528   -76  -72  -62  -73  -72  -84  -76  -75  -81\n",
      "529   -80  -72  -61  -78  -78  -76  -79  -78  -77\n",
      "530   -78  -69  -60  -68  -73  -78  -77  -76  -75\n",
      "531   -79  -70  -59  -73  -71  -78  -76  -72  -80\n",
      "532   -79  -70  -62  -71  -71  -82  -81  -72  -81\n",
      "533   -78  -70  -60  -83  -72  -89  -73  -78  -86\n",
      "534   -76  -72  -61  -76  -75  -78  -75  -71  -86\n",
      "535   -75  -69  -63  -77  -78  -84  -74  -77  -84\n",
      "536   -75  -70  -66  -73  -76  -84  -76  -81  -81\n",
      "537   -75  -71  -62  -70  -74  -90  -74  -77  -82\n",
      "538   -75  -72  -61  -71  -76  -85  -73  -77  -82\n",
      "539   -72  -69  -63  -75  -74  -78  -72  -71  -83\n",
      "540   -75  -71  -61  -78  -80  -80  -85  -82  -87\n",
      "541   -75  -70  -63  -76  -80  -80  -75 -105  -80\n",
      "542   -74  -71  -67  -80  -80  -74  -75  -74  -81\n",
      "543   -74  -74  -62  -77  -80  -80  -78  -74  -83\n",
      "544   -73  -74  -61  -96  -78  -74  -78  -74  -83\n",
      "594   -81  -89  -92 -105  -75  -72  -66 -105  -56\n",
      "595   -82  -85  -83  -86  -75  -72  -61  -61  -58\n",
      "596   -83  -83  -85  -84  -83  -72  -62  -65  -61\n",
      "597   -84  -82  -86  -82  -77  -72  -63  -65  -63\n",
      "598   -79  -82  -85  -80  -75  -72  -61  -63  -56\n",
      "599   -86  -86  -80  -82  -75  -73  -71  -67  -54\n",
      "600   -84  -92  -80  -89  -76  -73  -68  -63  -55\n",
      "601   -83  -86  -80  -81  -76  -76  -70  -66  -56\n",
      "602   -83  -86 -105  -90  -77  -74  -69  -76  -56\n",
      "603   -84  -91  -81  -89  -76  -74  -70  -63  -55\n",
      "604   -87 -105  -88  -89  -76  -73  -70  -63  -56\n",
      "605   -82  -86  -85  -81  -77  -73  -69  -70  -56\n",
      "606   -82  -87  -86  -81  -74  -75  -69  -75  -56\n",
      "607   -86 -100  -78  -85  -73  -76  -75  -56  -57\n",
      "608   -87  -91  -77  -85  -73  -77  -77  -56  -57\n",
      "609   -81  -93  -77  -81  -71  -76  -74  -57  -56\n",
      "610   -78  -86  -82  -81  -73  -76  -74  -56  -56\n",
      "660   -83  -81  -82  -74  -81  -77  -63  -72  -75\n",
      "661   -79  -78  -82  -72  -75  -68  -57  -70  -74\n",
      "662   -80  -76  -79  -74  -75  -69  -60  -63  -74\n",
      "663  -105  -78  -79  -73  -76  -69  -62  -67  -73\n",
      "664   -79  -78  -78  -77  -76  -69  -63  -67  -74\n",
      "665   -79  -78  -89  -74  -77  -80  -69  -62  -76\n",
      "666   -76  -78  -79  -75  -78  -76  -59  -76  -74\n",
      "667   -77  -80  -79  -77  -75  -76  -59  -70  -72\n",
      "668   -82  -82  -78  -77  -74  -71  -65  -72  -74\n",
      "669   -86  -82  -83  -74  -77  -70  -72  -70  -76\n",
      "670   -79  -78  -83  -74  -75  -73  -73  -70  -75\n",
      "671   -84  -77  -85  -70  -76  -81  -61  -66  -79\n",
      "672   -83  -81  -82  -71  -84  -78  -60  -68  -77\n",
      "673  -105  -78  -84  -71  -80  -76  -60  -76  -76\n",
      "674   -80  -78  -82  -73  -78  -77  -62  -76  -72\n",
      "675   -80  -77  -83  -70  -76  -76  -65  -72  -74\n",
      "676   -80  -82  -79  -74  -77  -72  -69  -78  -77\n",
      "729   -60  -56  -73  -74  -80  -83  -78  -77  -81\n",
      "730   -64  -57  -75  -74  -81  -81  -85  -72  -80\n",
      "731   -63  -59  -74  -78  -84  -82  -80  -70  -78\n",
      "732   -66  -61  -76  -80  -81  -82  -80  -71  -80\n",
      "733   -63  -62  -74  -77  -77  -81  -80  -71  -76\n",
      "734   -62  -60  -71  -75  -78  -79  -84  -74  -79\n",
      "735   -63  -62  -75  -76  -78  -82  -83  -73  -77\n",
      "736   -62  -63  -75  -77  -78  -80  -83  -72  -76\n",
      "737   -66  -65  -74  -78  -78  -80  -83  -79  -75\n",
      "738   -62  -65  -74  -80  -78  -80  -83  -71  -75\n",
      "739   -62  -65  -75  -79  -79  -80  -82  -71  -75\n",
      "740   -62  -68  -74  -80  -80  -78  -78  -71  -75\n",
      "741   -62  -71  -74  -80  -80  -79  -80  -70  -75\n",
      "742   -62  -70  -75  -80  -80  -79  -80  -70  -75\n",
      "743   -62  -71  -75  -80  -82  -79  -79  -70  -75\n",
      "744   -62  -63  -70  -80  -80  -79  -80  -70  -75\n",
      "745   -62  -60  -66  -79  -79  -77  -80  -74  -75\n",
      "746   -63  -63  -70  -80  -80  -82  -82  -75  -77\n",
      "747   -62  -61  -70  -77  -80  -82  -88  -74  -79\n",
      "748   -63  -61  -71  -78  -78  -81  -86  -76  -80\n",
      "749   -63  -63  -73  -81  -78  -82  -86  -75  -78\n",
      "750   -63  -65  -73  -78  -78  -82  -87  -74  -79\n",
      "751   -63  -63  -72  -80  -78  -82  -88  -74  -79\n",
      "752   -63  -66  -74  -80  -80  -83  -84  -75  -79\n",
      "753   -63  -63  -74  -80  -80  -84  -84  -73  -78\n",
      "754   -61  -61  -78  -80  -81  -81  -82  -73  -80\n",
      "755   -61  -60  -76  -80  -83  -84  -80  -74  -80\n",
      "756   -61  -61  -76  -80  -82  -82  -81  -72  -80\n",
      "757   -61  -61  -77  -82  -82  -82  -80  -72  -80\n",
      "845   -74  -69  -68  -74  -82  -76  -79  -72  -84\n",
      "846   -69  -70  -75  -82  -73  -77  -80  -78  -86\n",
      "847   -73  -74  -73  -78  -78  -82  -81  -78  -80\n",
      "848   -74  -71  -71  -77  -84  -76  -80  -78  -80\n",
      "849   -77  -69  -68  -81  -78  -83  -78  -75  -83\n",
      "850   -70  -70  -66  -74  -77  -82  -80  -81  -84\n",
      "851   -76  -71  -64  -76  -76  -82  -74  -78  -80\n",
      "852   -68  -66  -66  -75 -105  -79  -81  -76  -79\n",
      "853   -80  -70  -68  -82  -76  -83  -82  -97  -86\n",
      "854   -74  -67  -67  -80  -75  -80  -82  -76  -81\n",
      "855   -74  -68  -73  -86  -76  -80  -83  -76  -81\n",
      "856   -79  -68  -68  -80  -77  -83  -86  -90  -83\n",
      "857   -80  -68  -68  -80  -75  -81  -83  -85  -84\n",
      "858   -74  -68  -67  -85  -74  -79  -83  -75  -83\n",
      "859   -74  -68  -66  -85  -74  -79  -84  -75  -84\n",
      "860   -74  -67  -67  -80  -74  -79  -82  -76  -84\n",
      "861   -75  -68  -67  -82  -76  -80  -80  -76  -84\n",
      "911   -77  -59  -74  -73  -83  -82  -79  -75  -77\n",
      "912   -68  -61  -73  -71  -74  -74  -78  -76  -83\n",
      "913   -71  -62  -71  -77  -78  -84  -77  -73  -82\n",
      "914   -71  -62  -71  -76  -82  -87  -78  -74  -80\n",
      "915   -70  -63  -70  -77  -79  -83  -76  -75  -80\n",
      "916   -72  -66  -72  -78  -78  -91  -82  -76  -84\n",
      "917   -72  -65  -73  -78  -80  -86  -80  -76  -82\n",
      "918   -71  -65  -74  -82  -80  -88  -81  -75  -83\n",
      "919   -68  -64  -69  -74  -80  -81  -82  -77 -105\n",
      "920   -68  -77  -66  -82  -81  -83  -82  -71  -86\n",
      "921   -67  -64  -70  -77  -82  -84  -76  -85  -86\n",
      "922   -75  -67  -71  -77  -78  -88  -80  -84  -82\n",
      "923   -75  -61  -71  -78  -78  -91  -80 -105  -87\n",
      "924   -68  -62  -71  -86  -80  -83  -76  -77  -78\n",
      "925   -78  -62  -72  -90  -81  -83  -76  -75  -78\n",
      "926   -69  -62  -71  -79  -80 -105  -86  -74  -83\n",
      "978   -77  -72  -77  -76  -63  -74  -74  -70  -77\n",
      "979   -76  -77  -84  -82  -70  -75  -78  -70  -76\n",
      "980   -81  -77  -81  -78  -72  -82  -74  -69  -77\n",
      "981   -80  -76  -78  -73  -71  -79  -73  -70  -72\n",
      "982   -81  -76  -78  -72  -72  -80  -75  -68  -76\n",
      "983   -82  -80  -78  -73  -76  -83  -76  -70  -78\n",
      "984   -85  -72  -76  -72  -62  -76  -71  -69  -77\n",
      "985   -82  -80  -77  -80  -62  -77  -80  -68  -79\n",
      "986   -78  -80  -77  -85  -63  -76  -78  -67  -78\n",
      "987   -78  -89  -76  -75  -62  -75  -78  -69  -76\n",
      "988   -77  -88  -79  -74  -60  -76  -71  -67  -76\n",
      "989   -78  -82  -75  -72  -63  -76  -68  -72  -79\n",
      "990   -80  -74  -76  -72  -63  -76  -68  -70  -75\n",
      "991   -73  -74  -73  -72  -62  -73  -76  -66  -83\n",
      "992   -78  -78  -73  -78  -62  -83  -78  -72  -83\n",
      "993   -79  -78  -73  -72  -62  -75  -78  -71  -80\n",
      "1044  -88  -83  -78  -90  -82  -79  -70  -63  -79\n",
      "1045  -78  -84  -77  -80  -72  -72  -70  -62  -76\n",
      "1046  -85  -82  -79  -83  -76  -80  -70  -63  -74\n",
      "1047  -84  -83  -79  -84  -75  -79  -72  -63  -71\n",
      "1048  -76  -85  -77  -78  -72  -73  -67  -62  -73\n",
      "1049  -78  -84  -76  -80  -76  -82  -71  -62  -67\n",
      "1050  -79  -85  -80  -82  -73  -79  -68  -60  -71\n",
      "1051  -80  -90  -77  -80  -73  -72  -68  -61  -68\n",
      "1052  -84  -84  -80  -82  -75  -77  -69  -62  -68\n",
      "1053  -82  -86  -82  -78  -76  -75  -61  -60  -70\n",
      "1054  -78  -82  -74  -74  -72  -74  -69  -62  -66\n",
      "1055  -74  -86  -74  -80  -72  -67  -71  -61  -69\n",
      "1056  -73  -85  -73  -76  -69  -74  -60  -63  -79\n",
      "1057  -80  -82  -75  -80  -70  -73  -68  -66  -68\n",
      "1058  -83  -82  -83  -86  -73  -74  -65  -65  -69\n",
      "1059  -78  -86  -77  -82  -71  -70  -66  -62  -70\n",
      "1111  -68  -72  -71  -73  -83  -84  -81  -74  -80\n",
      "1112  -67  -72  -69  -73  -83  -84  -75  -76  -79\n",
      "1113  -65  -72  -70  -75  -84  -82  -82  -76  -80\n",
      "1114  -67  -80  -70  -77  -81  -80  -78  -76  -80\n",
      "1115  -67  -82  -70  -76  -81  -80  -79  -79  -80\n",
      "1116  -66  -81  -76  -76  -82  -80  -80  -80  -80\n",
      "1117  -66  -82  -71  -76  -81  -80  -80  -80  -89\n",
      "1118  -66  -82  -70  -77  -81  -80  -80  -79  -80\n",
      "1119  -66  -84  -70  -77  -81  -81  -78  -77  -78\n",
      "1120  -67  -84  -72  -74  -80  -80  -82  -78  -79\n",
      "1121  -67  -84  -72  -74  -80  -80  -80  -77  -78\n",
      "1122  -67  -83  -70  -75  -80  -80  -80  -77  -78\n",
      "1123  -65  -82  -70  -75  -80  -80  -79  -78  -78\n",
      "1124  -67  -82  -69  -75  -80  -80  -80  -76  -78\n",
      "1125  -67  -80  -69  -76  -81  -80  -78  -78  -78\n",
      "1126  -67  -80  -70  -76  -81  -80  -82  -80  -78\n",
      "1127  -68  -75  -72  -76  -81  -80  -84  -78  -78\n",
      "1128  -67  -75  -71  -76  -81  -80  -85  -78  -80\n",
      "1129  -67  -77  -72  -77  -80  -80  -85  -78  -80\n",
      "1130  -68  -80  -70  -77  -81  -79  -85  -80  -78\n",
      "1131  -66  -80  -71  -76  -80  -79  -85  -80  -78\n",
      "1132  -66  -78  -71  -74  -80  -78  -82  -80  -77\n",
      "1133  -65  -76  -73  -73  -81  -82  -82  -77  -81\n",
      "1134  -66  -83  -71  -76  -80  -80  -81  -77  -78\n",
      "1135  -66  -83  -72  -75  -81  -80  -83  -81  -78\n",
      "1136  -67  -82  -72  -74  -80  -80  -80  -78  -78\n",
      "1137  -67  -81  -71  -75  -81  -80  -79  -77  -79\n",
      "1138  -67  -81  -70  -76  -81  -80  -78  -76  -79\n",
      "1139  -67  -81  -71  -76  -81  -80  -78  -76  -79\n",
      "1227  -75  -71  -69  -68  -69  -74  -71  -70  -77\n",
      "1228  -77  -70  -68  -67  -70  -72  -69  -70  -86\n",
      "1229  -78  -75  -68  -69  -70  -72  -70  -70  -82\n",
      "1230  -79  -77  -70  -74  -71  -75  -74  -82  -82\n",
      "1231  -82  -77  -68  -69  -70  -69  -72  -69  -82\n",
      "1232  -80  -76  -67  -69  -70  -70  -71  -70  -83\n",
      "1233  -80  -76  -70  -74  -72  -74  -73  -80  -83\n",
      "1234  -80  -76  -70  -74  -70  -72  -75  -76  -78\n",
      "1235  -79  -74  -67  -69  -69  -72  -73  -75  -80\n",
      "1236  -80  -70  -68  -72  -71  -69  -67  -71  -78\n",
      "1237  -79  -70  -67  -76  -70  -73  -68  -74  -84\n",
      "1238  -75  -70  -69  -73  -68  -73  -71  -70  -80\n",
      "1239  -76  -74  -70  -73  -77  -76  -71  -73  -81\n",
      "1240  -75  -74  -70  -74  -80  -78  -73  -74  -81\n",
      "1241  -81  -70  -66  -70  -78  -76  -74  -76  -80\n",
      "1242  -84  -72  -68  -72  -75  -78  -71  -74  -79\n",
      "1243  -84  -72  -68  -73  -76  -76  -73  -75  -79\n",
      "1296  -67  -60  -72  -78  -79  -79  -76  -76  -77\n",
      "1297  -67  -63  -71  -74  -80  -79  -76  -77  -75\n",
      "1298  -65  -62  -69  -77  -78  -78  -78  -76  -79\n",
      "1299  -63  -63  -69  -74  -77  -79  -78  -75  -81\n",
      "1300  -62  -66  -71  -71  -78  -75  -82  -70  -76\n",
      "1301  -62  -66  -71  -73  -80  -80  -78  -71  -78\n",
      "1302  -62  -71  -73  -72  -81  -78  -78  -70  -78\n",
      "1303  -62  -70  -73  -71  -80  -77  -80  -71  -77\n",
      "1304  -62  -71  -73  -71  -79  -77  -82  -72  -77\n",
      "1305  -62  -70  -73  -71  -80  -78  -82  -70  -77\n",
      "1306  -62  -71  -73  -70  -80  -77  -82  -70  -76\n",
      "1307  -62  -72  -73  -69  -80  -77  -81  -70  -77\n",
      "1308  -61  -72  -73  -71  -80  -77  -81  -71  -77\n",
      "1309  -62  -72  -73  -69  -80  -78  -81  -71  -78\n",
      "1310  -61  -68  -74  -71  -80  -76  -80  -70  -77\n",
      "1311  -60  -68  -76  -72  -81  -78  -78  -69  -80\n",
      "1312  -62  -66  -72  -74  -83  -77  -80  -71  -74\n",
      "1313  -62  -68  -69  -73  -80  -80  -77  -72  -75\n",
      "1314  -66  -69  -69  -75  -84  -78  -74  -70  -76\n",
      "1315  -61  -67  -74  -82  -80  -84  -77  -72  -76\n",
      "1316  -62  -66  -73  -77  -80  -82  -77  -74  -80\n",
      "1317  -62  -66  -72  -79  -81  -82  -78  -71  -82\n",
      "1318  -63  -64  -71  -76  -80  -82  -79  -70  -80\n",
      "1319  -62  -65  -71  -76  -80  -82  -79  -71  -80\n",
      "1320  -62  -65  -70  -76  -80  -84  -80  -72  -80\n",
      "1321  -63  -64  -70  -75  -80  -83  -80  -71  -80\n",
      "1322  -64  -64  -69  -73  -82  -84  -81  -72  -80\n",
      "1323  -66  -65  -69  -73  -82  -84  -80  -70  -80\n",
      "1324  -62  -66  -71  -75  -80  -83  -80  -71  -78\n",
      "1412  -82  -84  -80  -76  -77  -71  -74  -63  -64\n",
      "1413  -78  -83  -80  -82  -72  -70  -72  -69  -68\n",
      "1414  -82  -86  -82  -80  -71  -62  -69  -66  -70\n",
      "1415  -81  -85  -85  -78  -69  -66  -72  -57  -70\n",
      "1416  -80  -87  -79  -79  -70  -61  -67  -60  -72\n",
      "1417  -85  -84  -83  -83  -70  -63  -68  -62  -64\n",
      "1418  -86  -84  -83  -85  -70  -62  -68  -62  -64\n",
      "1419  -84  -86  -83  -79  -71  -64  -70  -57  -62\n",
      "1420  -88  -84  -78 -105  -69  -64  -75  -58  -72\n",
      "1421  -80  -83  -79  -80  -73  -64  -72  -65  -78\n",
      "1422  -84  -82  -80  -82  -72  -62  -83  -63  -78\n",
      "1423  -86  -83  -78  -80  -70  -62  -70  -57  -71\n",
      "1424  -80  -90  -78  -80  -72  -62  -71  -65  -68\n",
      "1425  -74  -80  -81  -84  -69  -63  -69  -66  -63\n",
      "1426  -75  -88  -79  -77  -72  -69  -74  -75  -72\n",
      "1427  -77  -84  -81  -78  -77  -66  -75  -72  -73\n",
      "1428  -84  -88  -76  -79  -75  -68  -72  -67  -73\n",
      "1480  -83  -77  -85  -62  -68  -70  -69  -62  -75\n",
      "1481  -80  -95  -81  -67  -67  -80  -70  -71  -76\n",
      "1482  -81  -89  -84  -70  -69  -76  -67  -70  -74\n",
      "1483  -80  -92  -81  -69  -68  -70  -63  -68  -74\n",
      "1484  -76  -82  -82  -67  -68  -70  -62  -63  -72\n",
      "1485  -76  -86  -80  -70  -68  -70  -63  -63  -72\n",
      "1486  -75  -83  -83  -69  -66  -76  -62  -66  -70\n",
      "1487  -76  -87  -82  -69  -67  -85  -66  -66  -69\n",
      "1488  -79  -86  -81  -70  -69  -72  -67  -74  -72\n",
      "1489  -75  -90  -80  -70  -67  -81  -66  -78  -75\n",
      "1490  -76  -87  -81  -70  -66  -78  -63  -72  -75\n",
      "1491  -74  -82  -80  -68  -67  -73  -62  -66  -72\n",
      "1492  -76  -86  -82  -70  -67  -76  -62  -63  -70\n",
      "1493  -75  -88  -82  -70  -67  -76  -62  -66  -71\n",
      "1494  -78  -91  -80  -73  -69  -75  -65  -72  -76\n",
      "1495  -80  -93  -80  -71  -68  -76  -66  -70  -76\n",
      "1546  -75  -68  -73  -74  -77  -82  -80  -78  -87\n",
      "1547  -76  -72  -71  -78  -75  -90  -80  -77  -87\n",
      "1548  -78  -73  -67  -75  -84  -77  -92  -78  -78\n",
      "1549  -84  -70  -67  -72  -76  -74  -80  -77  -83\n",
      "1550  -84  -74  -76  -71  -77  -82  -81  -76  -82\n",
      "1551  -75  -70  -67  -71  -78  -74  -82  -76  -84\n",
      "1552  -88  -74  -67  -71  -78  -82  -83  -76  -82\n",
      "1553  -76  -70  -67  -71  -82  -74  -84  -75  -85\n",
      "1554  -76  -70  -68  -71  -81  -74  -84  -74  -80\n",
      "1555  -85  -74  -72  -72  -77  -83  -83  -75  -82\n",
      "1556  -86  -73  -71  -72  -78  -82  -83  -75  -81\n",
      "1557  -75  -70  -67  -70  -78  -74  -83  -75  -84\n",
      "1558  -76  -70  -67  -70  -77  -74  -84  -74  -84\n",
      "1559  -75  -73  -68  -73  -72  -80  -80  -78  -82\n",
      "1560  -74  -77  -67  -77  -67  -85  -80  -67  -77\n",
      "1561  -75  -77  -74  -75  -74  -81  -86  -74  -78\n",
      "1562  -75  -74  -76  -77  -72  -76  -85  -77  -80\n",
      "1613  -69  -68  -66  -74  -83  -77  -78  -76  -80\n",
      "1614  -65  -65  -60  -73  -80  -83  -85  -74  -84\n",
      "1615  -69  -67  -61  -75  -81  -81  -80  -74  -87\n",
      "1616  -71  -70  -62  -77  -82  -80  -86  -76  -86\n",
      "1617  -69  -68  -62  -76  -82  -83  -85  -72  -82\n",
      "1618  -69  -69  -63  -79  -83  -84  -83  -72  -81\n",
      "1619  -67  -69  -62  -78  -82  -83  -86  -73  -82\n",
      "1620  -69  -70  -62  -79  -81  -82  -85  -74  -84\n",
      "1621  -70  -68  -66  -79  -82  -84  -86  -71  -84\n",
      "1622  -67  -71  -61  -74  -85  -82  -83  -76  -80\n",
      "1623  -69  -68  -67  -77  -78  -78  -83  -75  -78\n",
      "1624  -69  -67  -60  -79  -82  -82  -80  -73  -85\n",
      "1625  -69  -66  -61  -81  -81  -87  -81  -75  -88\n",
      "1626  -68  -68  -63  -79  -81  -87  -82  -75  -92\n",
      "1627  -69  -67  -62  -81  -81  -88  -84  -77  -96\n",
      "1628  -66  -66  -62  -79  -82  -90  -83  -75  -82\n",
      "1629  -66  -64  -62  -80  -83  -85  -78  -75  -83\n",
      "1630  -70  -65  -60  -72  -80  -84  -78  -77  -82\n",
      "1631  -67  -68  -61  -75  -79  -83  -88  -77  -79\n",
      "1632  -67  -68  -60  -74  -80  -80  -82  -77  -80\n",
      "1633  -67  -70  -61  -73  -81  -82  -82  -81  -77\n",
      "1634  -66  -68  -60  -75  -82  -85  -82  -78  -79\n",
      "1635  -66  -69  -61  -76  -84  -88  -84  -76  -78\n",
      "1636  -72  -71  -61  -77  -82  -81  -86  -80  -81\n",
      "1637  -68  -70  -62  -74  -84  -82  -83  -81  -80\n",
      "1638  -69  -70  -60  -75  -83  -80  -81  -82  -81\n",
      "1639  -72  -69  -60  -78  -84  -80  -82  -85  -87\n",
      "1640  -71  -68  -61  -75  -83  -79  -84  -78  -83\n",
      "1641  -71  -68  -63  -74  -83  -81  -90  -76  -83\n",
      "1729  -72  -65  -77  -74  -81  -80  -77  -76  -80\n",
      "1730  -76  -72  -77  -80  -77  -79  -76  -75  -83\n",
      "1731  -74  -72  -76  -82  -76  -78  -77  -74  -86\n",
      "1732  -74  -74  -76  -82  -89  -81  -77  -76  -86\n",
      "1733  -72  -74  -79  -81  -77  -81  -77  -74  -89\n",
      "1734  -71  -73  -78  -82  -77  -82  -78  -73  -91\n",
      "1735  -73  -73  -78  -81  -76  -80  -78  -75  -88\n",
      "1736  -72  -72  -79  -80  -76  -81  -78  -73  -88\n",
      "1737  -77  -72  -78  -81  -76  -80  -77  -72  -90\n",
      "1738  -73  -73  -78  -81  -76  -82  -77  -74  -90\n",
      "1739  -71  -74  -78  -82  -77  -81  -78  -73  -88\n",
      "1740  -69  -74  -78  -83  -77  -82  -80  -72  -91\n",
      "1741  -72  -73  -79  -82  -76  -82  -77  -73  -92\n",
      "1742  -72  -73  -79  -82  -77  -82  -78  -72  -91\n",
      "1743  -71  -73  -78  -82  -77  -82  -79  -72  -93\n",
      "1744  -73  -71  -78  -82  -76  -79  -77  -73  -86\n",
      "1745  -69  -73  -74  -77  -78  -80  -77  -72  -80\n",
      "1746  -74  -74  -77  -82  -77  -78  -76  -73  -83\n",
      "1747  -72  -73  -78  -82  -77  -78  -76  -74  -88\n",
      "1748  -76  -73  -79  -81  -77  -78  -77  -76  -91\n",
      "1749  -75  -72  -78  -80  -78  -77  -75  -74  -86\n",
      "1750  -74  -71  -80  -80  -77  -77  -76  -75  -86\n",
      "1751  -74  -74  -82  -83  -78  -78  -77  -78  -87\n",
      "1752  -74  -75  -78  -81  -87  -78  -77  -76  -88\n",
      "1753  -74  -75  -78  -81  -77  -78  -76  -76  -86\n",
      "1754  -74  -74  -76  -80  -78  -79  -77  -77  -83\n",
      "1755  -74  -76  -75  -79  -78  -80  -77  -74  -81\n",
      "1756  -74  -76  -77  -81  -78  -80  -77  -77  -84\n",
      "1757  -74  -73  -77  -81  -79  -79  -77  -76  -84\n",
      "1845  -87  -87  -80  -74  -77  -71  -60  -71  -63\n",
      "1846  -80  -82  -85  -79  -83  -71  -69  -63  -62\n",
      "1847  -78  -85  -84  -80  -83  -70  -69  -61  -65\n",
      "1848  -76  -96  -82  -80  -80  -74  -68  -69  -68\n",
      "1849  -78  -88  -83  -80  -80  -73  -69  -67  -72\n",
      "1850  -80  -81  -84  -78  -78  -73  -75  -71  -72\n",
      "1851  -76  -79  -79  -72  -79  -71  -67  -71  -68\n",
      "1852  -76  -82  -87  -76  -78  -68  -67  -66  -66\n",
      "1853  -76  -82  -82  -77  -78  -71  -63  -68  -68\n",
      "1854  -77  -82  -86  -78  -85  -71  -63  -67  -69\n",
      "1855  -77  -80  -84  -76  -79  -75  -67  -72  -71\n",
      "1856  -77  -82  -85  -78  -80  -74  -65  -70  -73\n",
      "1857  -80  -83  -94  -77  -76  -72  -65  -68  -70\n",
      "1858  -81  -82  -85  -77  -78  -70  -66  -67  -67\n",
      "1859  -76 -105  -82  -76  -82  -72  -67  -69  -72\n",
      "1860  -82  -83  -90 -105  -78  -72  -63  -69  -70\n",
      "1909  -80  -79  -82  -82  -74  -68  -67  -68  -72\n",
      "1910  -78  -86  -82  -72  -72  -70  -62  -73  -80\n",
      "1911  -76  -84  -84  -73  -78  -70  -60  -72  -78\n",
      "1912  -78  -85  -83  -78  -71  -80  -68  -72  -74\n",
      "1913  -76  -89  -79  -81  -71  -73  -65  -89  -74\n",
      "1914  -78  -85  -78  -80  -72  -74  -66  -69  -73\n",
      "1915  -76 -105  -80  -76  -76  -74  -72  -69  -75\n",
      "1916  -76  -74  -81  -83  -74  -76  -62  -79  -72\n",
      "1917  -76  -72  -82  -81  -76  -71  -62  -76  -78\n",
      "1918  -82  -74  -86  -78  -76  -76  -67  -75  -77\n",
      "1919  -80  -76  -83  -96  -75  -76  -61 -105  -77\n",
      "1920  -77  -74  -82  -80  -76  -74  -63  -82  -75\n",
      "1921  -76  -74  -84  -78  -76  -80  -67  -73  -76\n",
      "1922  -76  -86  -76  -76  -77  -69  -62  -74  -78\n",
      "1923  -75  -79  -82  -77  -74  -70  -61  -70  -74\n",
      "1924  -80  -78  -82  -77  -73  -70  -60  -71  -72\n",
      "1925  -79  -79  -77  -83  -74  -71  -62  -79  -74\n",
      "1926  -79  -81  -84  -79  -73  -72  -73  -68  -75\n",
      "1974  -63  -74  -67  -76  -78  -78  -80  -76  -84\n",
      "1975  -62  -70  -66  -73  -84  -75  -84  -78  -79\n",
      "1976  -63  -72  -73  -74  -83  -80  -84  -78  -80\n",
      "1977  -63  -73  -75  -75  -84  -80  -86  -75  -81\n",
      "1978  -63  -76  -74  -75  -83  -80  -82  -79  -80\n",
      "1979  -63  -76  -76  -74  -82  -81  -82  -78  -80\n",
      "1980  -63  -77  -75  -74  -87  -81  -84  -74  -81\n",
      "1981  -63  -78  -74  -76  -84  -81  -82  -76  -80\n",
      "1982  -63  -77  -74  -76  -83  -81  -82  -76  -80\n",
      "1983  -68  -78  -75  -76  -85  -80  -83  -74  -80\n",
      "1984  -63  -78  -74  -76  -84  -80  -84  -75  -80\n",
      "1985  -64  -78  -72  -76  -85  -79  -84  -74  -80\n",
      "1986  -63  -77  -69  -76  -85  -79  -80  -72  -80\n",
      "1987  -64  -80  -70  -76  -84  -78  -80  -72  -80\n",
      "1988  -66  -82  -70  -78  -87  -77  -84  -74  -83\n",
      "1989  -66  -80  -68  -78  -87  -76  -83  -73  -82\n",
      "1990  -64  -83  -67  -80  -86  -77  -82  -71  -82\n",
      "1991  -65  -81  -68  -77  -87  -77  -85  -71  -82\n",
      "1992  -66  -80  -67  -76  -86  -78  -83  -75  -82\n",
      "1993  -66  -79  -68  -82  -86  -77  -83  -73  -83\n",
      "1994  -64  -80  -69  -77  -86  -78  -84  -73  -82\n",
      "1995  -66  -82  -68  -77  -88  -78  -83  -72  -84\n",
      "1996  -66  -84  -67  -77  -85  -78  -82  -73  -83\n",
      "1997  -66  -82  -68  -77  -86  -78  -82  -73  -84\n",
      "1998  -66  -82  -67  -77  -85  -78  -82  -72  -86\n",
      "1999  -66  -79  -67  -76  -86  -79  -82  -76  -84\n",
      "2000  -67  -77  -67  -76  -86  -79  -83  -76  -84\n",
      "2001  -67  -77  -67  -76  -87  -78  -81  -74  -83\n",
      "2002  -66  -83  -67  -77  -85  -78  -80  -72  -83>\n",
      "(521, 9)\n",
      "(521,)\n"
     ]
    }
   ],
   "source": [
    "df = df[df['Direction'] == 'norte']\n",
    "df =  df.drop(columns = ['Direction', 'Alpha', 'Beta', 'Gama', 'Device', 'Brand', 'Created', 'Model' ])\n",
    "X = df.drop(columns = ['X', 'Y', 'RP'])\n",
    "Y = df[\"RP\"]\n",
    "\n",
    "print(X.head)\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "17a58065",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X['Direction'] = X['Direction'].replace('norte', 1)\n",
    "#X['Direction'] = X['Direction'].replace('leste', 2)\n",
    "#X['Direction'] = X['Direction'].replace('sul', 3)\n",
    "#X['Direction'] = X['Direction'].replace('oeste', 4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6906c05b",
   "metadata": {},
   "source": [
    "Bibliotecas para o treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "d27c16ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "a9d51317",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.to_numpy()\n",
    "Y = Y.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "590c245f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sementes aletórios para divisão do treino: [19, 47, 45, 83, 69]\n",
      "Iniciando a divisão com a semente seed1: 19\n",
      "Iniciando a divisão com a semente seed2: 47\n",
      "Iniciando a divisão com a semente seed3: 45\n",
      "Iniciando a divisão com a semente seed4: 83\n",
      "Iniciando a divisão com a semente seed5: 69\n"
     ]
    }
   ],
   "source": [
    "lower_limit = 1\n",
    "upper_limit = 100\n",
    "\n",
    "seed_labels = [\"seed1\", \"seed2\", \"seed3\", \"seed4\", \"seed5\"]\n",
    "\n",
    "sets_division = {\n",
    "    label: {\"seed\":\"\", \"X_train\":\"\", \"X_test\":\"\", \"Y_train\":\"\", \"Y_test\":\"\"}\n",
    "    for label in seed_labels\n",
    "}\n",
    "\n",
    "\n",
    "random_state = [random.randint(lower_limit, upper_limit) for _ in range(len(sets_division))]\n",
    "print(f\"Sementes aletórios para divisão do treino: {random_state}\")\n",
    "\n",
    "\n",
    "index_seed = 0\n",
    "for seed, set_division in sets_division.items():\n",
    "   print(f\"Iniciando a divisão com a semente {seed}: {random_state[index_seed]}\")\n",
    "\n",
    "   set_division[\"seed\"] = random_state[index_seed]\n",
    "   set_division[\"X_train\"], set_division[\"X_test\"], set_division[\"Y_train\"], set_division[\"Y_test\"] = train_test_split(X, Y, test_size=0.3, random_state=random_state[index_seed], stratify=Y)\n",
    "\n",
    "   index_seed += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "2f12703f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits = 5, shuffle = True, random_state=42)\n",
    "param_grid = {'n_neighbors':[1,3,5,7,9,11]}\n",
    "knn_clf = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "329661f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n TESTE PARA VER SE ESTAVA FUNCIONANDO\\n \\nX_train = sets_division[\"seed1\"][\"X_train\"]\\nX_test = sets_division[\"seed1\"][\"X_test\"]\\nY_train = sets_division[\"seed1\"][\"Y_train\"]\\nY_test = sets_division[\"seed1\"][\"Y_test\"]\\n\\nprint(f\"(SHAPES)\\nX_train: {X_train.shape}; \\nX_test: {X_test.shape}; \\nY_train: {Y_train.shape}; \\nY_test: {Y_test.shape}\")\\n\\nbest_k, best_knn = get_best_k_model(model=knn_clf, x_fit=X_train, y_fit=Y_train, parametros=param_grid,\\n                                    estrategia_treinamento=cv, reference_metric=\"accuracy\", processos_de_cpu=1)\\n\\nprint(f\"Melhor k encontrado para o KNN: {best_k}\")\\nprint(best_knn)\\n'"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_best_k_model(model, x_fit, y_fit, parametros, estrategia_treinamento, reference_metric, processos_de_cpu):\n",
    "    \n",
    "    grid_search_class = GridSearchCV(estimator=model, param_grid=parametros, cv=estrategia_treinamento, scoring=reference_metric, n_jobs = processos_de_cpu)\n",
    "    grid_search_class.fit(x_fit, y_fit)\n",
    "    best_k = grid_search_class.best_params_['n_neighbors']\n",
    "    best_knn_clf = grid_search_class.best_estimator_\n",
    "    \n",
    "    return  best_k, best_knn_clf\n",
    "\n",
    "\n",
    "'''\n",
    " TESTE PARA VER SE ESTAVA FUNCIONANDO\n",
    " \n",
    "X_train = sets_division[\"seed1\"][\"X_train\"]\n",
    "X_test = sets_division[\"seed1\"][\"X_test\"]\n",
    "Y_train = sets_division[\"seed1\"][\"Y_train\"]\n",
    "Y_test = sets_division[\"seed1\"][\"Y_test\"]\n",
    "\n",
    "print(f\"(SHAPES)\\nX_train: {X_train.shape}; \\nX_test: {X_test.shape}; \\nY_train: {Y_train.shape}; \\nY_test: {Y_test.shape}\")\n",
    "\n",
    "best_k, best_knn = get_best_k_model(model=knn_clf, x_fit=X_train, y_fit=Y_train, parametros=param_grid,\n",
    "                                    estrategia_treinamento=cv, reference_metric=\"accuracy\", processos_de_cpu=1)\n",
    "\n",
    "print(f\"Melhor k encontrado para o KNN: {best_k}\")\n",
    "print(best_knn)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a8ecad",
   "metadata": {},
   "source": [
    "# Predicao"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80ca8d5",
   "metadata": {},
   "source": [
    "conjunto dos valores x y para cada posicao de classificacao P_X_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "75315eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(521,)\n",
      "{'1': 1.57, '2': 3.92, '3': 6.27}\n",
      "{'1': 0.77, '2': 2.03, '3': 3.76, '4': 5.42, '5': 7.09, '6': 8.75, '7': 10.42, '8': 12.08, '9': 13.74}\n"
     ]
    }
   ],
   "source": [
    "df_rp = df[\"RP\"].to_numpy()\n",
    "categories = np.unique(df_rp)\n",
    "print(df_rp.shape)\n",
    "\n",
    "sets_positions = {'X':{}, \"Y\":{}}\n",
    "\n",
    "for categorie in categories:\n",
    "    \n",
    "    first_record_category = df.loc[df['RP'] == categorie].iloc[0]\n",
    "    \n",
    "    \n",
    "    y = float(first_record_category[\"Y\"])\n",
    "    x = float(first_record_category[\"X\"])\n",
    "\n",
    "\n",
    "    split_categorie = categorie.split(\"_\")\n",
    "    #print(split_categorie)\n",
    "\n",
    "    if(split_categorie[1] not in sets_positions[\"Y\"]):\n",
    "        #print(f\"Adicionando o valor {y} associado a P_{split_categorie[1]}_x\")\n",
    "        sets_positions[\"Y\"][f\"{split_categorie[1]}\"] = y\n",
    "\n",
    "    if(split_categorie[2] not in sets_positions[\"X\"]):\n",
    "        #print(f\"Adicionando o valor {x} associado a P_Y_{split_categorie[2]}\")\n",
    "        sets_positions[\"X\"][f\"{split_categorie[2]}\"] = x\n",
    "    \n",
    "\n",
    "\n",
    "print(sets_positions[\"X\"])\n",
    "print(sets_positions[\"Y\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "c3e81cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def converte_categoria_posicao(values_pred,values_real):\n",
    "    posicoes_pred = []\n",
    "    posicoes_real = []\n",
    "    shape_pred = values_pred.shape[0]\n",
    "    shape_real = values_real.shape[0]\n",
    "\n",
    "    if(shape_pred != shape_real):\n",
    "        print(f\"Erro a dimensão dos valores previstos é diferente da dimensão dos valores reais: (pred {values_pred}) (real {values_real})\")\n",
    "        return\n",
    "    \n",
    "    for index in range(len(values_real)):\n",
    "\n",
    "        value_pred_split = values_pred[index].split(\"_\")\n",
    "        value_real_split = values_real[index].split(\"_\")\n",
    "\n",
    "        x_pred = sets_positions['X'][value_pred_split[2]]\n",
    "        y_pred = sets_positions['Y'][value_pred_split[1]]\n",
    "        x_real = sets_positions['X'][value_real_split[2]]\n",
    "        y_real = sets_positions['Y'][value_real_split[1]]\n",
    "\n",
    "        posicoes_pred.append((x_pred, y_pred))\n",
    "        posicoes_real.append((x_real, y_real))\n",
    "\n",
    "    return posicoes_pred, posicoes_real\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "380fcdd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================== TREINAMENTO COM BASE NA DIVISÃO DA SEMENTE seed1: 19 =======================\n",
      "(SHAPES)\n",
      "X_train: (364, 9); \n",
      "X_test: (157, 9); \n",
      "Y_train: (364,); \n",
      "Y_test: (157,);\n",
      "\n",
      "Melhor k encontrado para o KNN: 1\n",
      "\n",
      "Erro médio absoluto da distância euclidiana entre os valores preditos e os valores reais: 0.64\n",
      "------------------------------------------------------------\n",
      "RESULTADOS DA CLASSIFICAÇÃO (PR) - Melhor K: 1\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       P_1_1       0.89      1.00      0.94         8\n",
      "       P_1_2       1.00      1.00      1.00         9\n",
      "       P_1_3       1.00      1.00      1.00         9\n",
      "       P_2_1       1.00      1.00      1.00         9\n",
      "       P_2_2       0.73      1.00      0.84         8\n",
      "       P_2_3       0.89      0.89      0.89         9\n",
      "       P_3_1       1.00      0.60      0.75         5\n",
      "       P_3_2       0.62      1.00      0.77         5\n",
      "       P_3_3       1.00      1.00      1.00         5\n",
      "       P_4_1       0.80      0.80      0.80         5\n",
      "       P_4_2       0.67      0.40      0.50         5\n",
      "       P_4_3       1.00      0.60      0.75         5\n",
      "       P_5_1       1.00      0.40      0.57         5\n",
      "       P_5_2       0.71      1.00      0.83         5\n",
      "       P_5_3       0.67      0.40      0.50         5\n",
      "       P_6_1       0.67      0.80      0.73         5\n",
      "       P_6_2       0.50      0.20      0.29         5\n",
      "       P_6_3       0.71      1.00      0.83         5\n",
      "       P_7_1       0.75      0.60      0.67         5\n",
      "       P_7_2       0.83      1.00      0.91         5\n",
      "       P_7_3       0.67      0.80      0.73         5\n",
      "       P_8_1       1.00      0.40      0.57         5\n",
      "       P_8_2       0.75      0.60      0.67         5\n",
      "       P_8_3       0.57      0.80      0.67         5\n",
      "       P_9_1       0.50      0.80      0.62         5\n",
      "       P_9_2       1.00      1.00      1.00         5\n",
      "       P_9_3       0.60      0.60      0.60         5\n",
      "\n",
      "    accuracy                           0.80       157\n",
      "   macro avg       0.80      0.77      0.76       157\n",
      "weighted avg       0.82      0.80      0.78       157\n",
      "\n",
      "\n",
      "===================== TREINAMENTO COM BASE NA DIVISÃO DA SEMENTE seed2: 47 =======================\n",
      "(SHAPES)\n",
      "X_train: (364, 9); \n",
      "X_test: (157, 9); \n",
      "Y_train: (364,); \n",
      "Y_test: (157,);\n",
      "\n",
      "Melhor k encontrado para o KNN: 1\n",
      "\n",
      "Erro médio absoluto da distância euclidiana entre os valores preditos e os valores reais: 0.66\n",
      "------------------------------------------------------------\n",
      "RESULTADOS DA CLASSIFICAÇÃO (PR) - Melhor K: 1\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       P_1_1       1.00      1.00      1.00         8\n",
      "       P_1_2       1.00      1.00      1.00         9\n",
      "       P_1_3       1.00      1.00      1.00         9\n",
      "       P_2_1       1.00      1.00      1.00         9\n",
      "       P_2_2       0.89      1.00      0.94         8\n",
      "       P_2_3       0.78      0.78      0.78         9\n",
      "       P_3_1       1.00      0.60      0.75         5\n",
      "       P_3_2       0.44      0.80      0.57         5\n",
      "       P_3_3       1.00      1.00      1.00         5\n",
      "       P_4_1       0.60      0.60      0.60         5\n",
      "       P_4_2       0.50      0.20      0.29         5\n",
      "       P_4_3       0.75      0.60      0.67         5\n",
      "       P_5_1       0.75      0.60      0.67         5\n",
      "       P_5_2       0.71      1.00      0.83         5\n",
      "       P_5_3       0.40      0.40      0.40         5\n",
      "       P_6_1       1.00      0.60      0.75         5\n",
      "       P_6_2       0.75      0.60      0.67         5\n",
      "       P_6_3       1.00      0.80      0.89         5\n",
      "       P_7_1       0.71      1.00      0.83         5\n",
      "       P_7_2       1.00      1.00      1.00         5\n",
      "       P_7_3       0.67      0.80      0.73         5\n",
      "       P_8_1       0.80      0.80      0.80         5\n",
      "       P_8_2       0.56      1.00      0.71         5\n",
      "       P_8_3       0.67      0.40      0.50         5\n",
      "       P_9_1       0.00      0.00      0.00         5\n",
      "       P_9_2       1.00      1.00      1.00         5\n",
      "       P_9_3       0.62      1.00      0.77         5\n",
      "\n",
      "    accuracy                           0.79       157\n",
      "   macro avg       0.76      0.76      0.75       157\n",
      "weighted avg       0.79      0.79      0.77       157\n",
      "\n",
      "\n",
      "===================== TREINAMENTO COM BASE NA DIVISÃO DA SEMENTE seed3: 45 =======================\n",
      "(SHAPES)\n",
      "X_train: (364, 9); \n",
      "X_test: (157, 9); \n",
      "Y_train: (364,); \n",
      "Y_test: (157,);\n",
      "\n",
      "Melhor k encontrado para o KNN: 1\n",
      "\n",
      "Erro médio absoluto da distância euclidiana entre os valores preditos e os valores reais: 0.60\n",
      "------------------------------------------------------------\n",
      "RESULTADOS DA CLASSIFICAÇÃO (PR) - Melhor K: 1\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       P_1_1       1.00      1.00      1.00         9\n",
      "       P_1_2       1.00      1.00      1.00         9\n",
      "       P_1_3       1.00      1.00      1.00         9\n",
      "       P_2_1       1.00      1.00      1.00         8\n",
      "       P_2_2       1.00      1.00      1.00         8\n",
      "       P_2_3       0.80      0.89      0.84         9\n",
      "       P_3_1       1.00      0.40      0.57         5\n",
      "       P_3_2       0.57      0.80      0.67         5\n",
      "       P_3_3       1.00      1.00      1.00         5\n",
      "       P_4_1       1.00      0.80      0.89         5\n",
      "       P_4_2       0.71      1.00      0.83         5\n",
      "       P_4_3       0.60      0.60      0.60         5\n",
      "       P_5_1       0.60      0.60      0.60         5\n",
      "       P_5_2       0.50      0.60      0.55         5\n",
      "       P_5_3       0.33      0.40      0.36         5\n",
      "       P_6_1       0.50      0.40      0.44         5\n",
      "       P_6_2       1.00      0.60      0.75         5\n",
      "       P_6_3       1.00      0.80      0.89         5\n",
      "       P_7_1       1.00      0.60      0.75         5\n",
      "       P_7_2       1.00      1.00      1.00         5\n",
      "       P_7_3       0.62      1.00      0.77         5\n",
      "       P_8_1       1.00      0.40      0.57         5\n",
      "       P_8_2       0.67      0.80      0.73         5\n",
      "       P_8_3       0.80      0.80      0.80         5\n",
      "       P_9_1       0.38      0.60      0.46         5\n",
      "       P_9_2       1.00      1.00      1.00         5\n",
      "       P_9_3       1.00      0.80      0.89         5\n",
      "\n",
      "    accuracy                           0.80       157\n",
      "   macro avg       0.82      0.77      0.78       157\n",
      "weighted avg       0.84      0.80      0.80       157\n",
      "\n",
      "\n",
      "===================== TREINAMENTO COM BASE NA DIVISÃO DA SEMENTE seed4: 83 =======================\n",
      "(SHAPES)\n",
      "X_train: (364, 9); \n",
      "X_test: (157, 9); \n",
      "Y_train: (364,); \n",
      "Y_test: (157,);\n",
      "\n",
      "Melhor k encontrado para o KNN: 1\n",
      "\n",
      "Erro médio absoluto da distância euclidiana entre os valores preditos e os valores reais: 0.61\n",
      "------------------------------------------------------------\n",
      "RESULTADOS DA CLASSIFICAÇÃO (PR) - Melhor K: 1\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       P_1_1       1.00      1.00      1.00         9\n",
      "       P_1_2       0.88      0.88      0.88         8\n",
      "       P_1_3       0.82      1.00      0.90         9\n",
      "       P_2_1       1.00      1.00      1.00         9\n",
      "       P_2_2       0.90      1.00      0.95         9\n",
      "       P_2_3       1.00      1.00      1.00         8\n",
      "       P_3_1       0.80      0.80      0.80         5\n",
      "       P_3_2       0.75      0.60      0.67         5\n",
      "       P_3_3       0.83      1.00      0.91         5\n",
      "       P_4_1       0.67      0.80      0.73         5\n",
      "       P_4_2       1.00      0.60      0.75         5\n",
      "       P_4_3       0.67      0.80      0.73         5\n",
      "       P_5_1       0.50      0.20      0.29         5\n",
      "       P_5_2       0.83      1.00      0.91         5\n",
      "       P_5_3       0.50      0.60      0.55         5\n",
      "       P_6_1       0.60      0.60      0.60         5\n",
      "       P_6_2       0.60      0.60      0.60         5\n",
      "       P_6_3       0.75      0.60      0.67         5\n",
      "       P_7_1       1.00      0.80      0.89         5\n",
      "       P_7_2       1.00      1.00      1.00         5\n",
      "       P_7_3       0.33      0.40      0.36         5\n",
      "       P_8_1       0.80      0.80      0.80         5\n",
      "       P_8_2       0.62      1.00      0.77         5\n",
      "       P_8_3       0.67      0.40      0.50         5\n",
      "       P_9_1       0.40      0.40      0.40         5\n",
      "       P_9_2       1.00      0.80      0.89         5\n",
      "       P_9_3       0.75      0.60      0.67         5\n",
      "\n",
      "    accuracy                           0.78       157\n",
      "   macro avg       0.77      0.75      0.75       157\n",
      "weighted avg       0.79      0.78      0.78       157\n",
      "\n",
      "\n",
      "===================== TREINAMENTO COM BASE NA DIVISÃO DA SEMENTE seed5: 69 =======================\n",
      "(SHAPES)\n",
      "X_train: (364, 9); \n",
      "X_test: (157, 9); \n",
      "Y_train: (364,); \n",
      "Y_test: (157,);\n",
      "\n",
      "Melhor k encontrado para o KNN: 1\n",
      "\n",
      "Erro médio absoluto da distância euclidiana entre os valores preditos e os valores reais: 0.59\n",
      "------------------------------------------------------------\n",
      "RESULTADOS DA CLASSIFICAÇÃO (PR) - Melhor K: 1\n",
      "------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       P_1_1       0.90      1.00      0.95         9\n",
      "       P_1_2       1.00      0.89      0.94         9\n",
      "       P_1_3       0.82      1.00      0.90         9\n",
      "       P_2_1       1.00      1.00      1.00         8\n",
      "       P_2_2       1.00      0.88      0.93         8\n",
      "       P_2_3       0.82      1.00      0.90         9\n",
      "       P_3_1       0.50      0.20      0.29         5\n",
      "       P_3_2       0.38      0.60      0.46         5\n",
      "       P_3_3       1.00      0.60      0.75         5\n",
      "       P_4_1       0.67      0.80      0.73         5\n",
      "       P_4_2       0.67      0.40      0.50         5\n",
      "       P_4_3       0.43      0.60      0.50         5\n",
      "       P_5_1       0.50      0.60      0.55         5\n",
      "       P_5_2       0.83      1.00      0.91         5\n",
      "       P_5_3       1.00      0.20      0.33         5\n",
      "       P_6_1       1.00      0.60      0.75         5\n",
      "       P_6_2       1.00      0.60      0.75         5\n",
      "       P_6_3       0.83      1.00      0.91         5\n",
      "       P_7_1       0.80      0.80      0.80         5\n",
      "       P_7_2       0.71      1.00      0.83         5\n",
      "       P_7_3       0.83      1.00      0.91         5\n",
      "       P_8_1       0.75      0.60      0.67         5\n",
      "       P_8_2       0.62      1.00      0.77         5\n",
      "       P_8_3       0.80      0.80      0.80         5\n",
      "       P_9_1       0.25      0.20      0.22         5\n",
      "       P_9_2       1.00      1.00      1.00         5\n",
      "       P_9_3       1.00      0.80      0.89         5\n",
      "\n",
      "    accuracy                           0.78       157\n",
      "   macro avg       0.78      0.75      0.74       157\n",
      "weighted avg       0.80      0.78      0.77       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "set_positions_seed = {}\n",
    "set_test_pred_categories = {}\n",
    "\n",
    "for seed, division in sets_division.items():\n",
    "\n",
    "    print(f\"\\n===================== TREINAMENTO COM BASE NA DIVISÃO DA SEMENTE {seed}: {division['seed']} =======================\")\n",
    "\n",
    "    #Divisao dos dados de acordo como foi dividido por cada semente\n",
    "    X_train = division[\"X_train\"]\n",
    "    X_test = division[\"X_test\"]\n",
    "    Y_train = division[\"Y_train\"]\n",
    "    Y_test = division[\"Y_test\"]\n",
    "\n",
    "    print(f\"(SHAPES)\\nX_train: {X_train.shape}; \\nX_test: {X_test.shape}; \\nY_train: {Y_train.shape}; \\nY_test: {Y_test.shape};\")\n",
    "\n",
    "    #Busca em grade para o melhor K, e modelo do KNN com base na acurácia, e nos dados de treino e teste\n",
    "    best_k, best_knn = get_best_k_model(model=knn_clf, x_fit=X_train, y_fit=Y_train, parametros=param_grid,\n",
    "                                        estrategia_treinamento=cv, reference_metric=\"accuracy\", processos_de_cpu=1)\n",
    "    print(f\"\\nMelhor k encontrado para o KNN: {best_k}\")\n",
    "\n",
    "\n",
    "    #Predicao dos valores utilizando o modelo selecionado pela busca em grade pelo melhor modelo\n",
    "    Y_pred = best_knn.predict(X_test)\n",
    "    set_test_pred_categories[seed] =  {'seed':division['seed'],'values_pred':Y_pred, 'values_test':Y_test}\n",
    "\n",
    "    # Conversão dos valores da categorias para x e y para poder fazer os calculos\n",
    "    positions_pred, positions_test = converte_categoria_posicao(Y_pred, Y_test)\n",
    "    preditos = np.array(positions_pred)\n",
    "    reais = np.array(positions_test)\n",
    "    \n",
    "    #adicionando em uma estrutura para poder fazer os plots para melhor analise do desempenho do modelo\n",
    "    set_positions_seed[seed] = {'seed':division['seed'],'positions_pred':preditos, 'positions_test':reais}\n",
    "    \n",
    "    #calculo do erro medio da distancia euclidiana entre os pontos \n",
    "    # Di = raiz((Xi_pred - Xi_real)ˆ2 + (Yi_pred - Yireal)ˆ2)\n",
    "    # MAE = (|D1| + ... + |DN|)/N\n",
    "\n",
    "    distancias = np.sqrt((preditos[:, 0] - reais[:, 0])**2 + (preditos[:, 1] - reais[:, 1])**2)\n",
    "    mae = np.mean(distancias)\n",
    "\n",
    "\n",
    "    print(f\"\\nErro médio absoluto da distância euclidiana entre os valores preditos e os valores reais: {mae:.2f}\")\n",
    "\n",
    "\n",
    "    print(\"-\"*60)\n",
    "    print(f\"RESULTADOS DA CLASSIFICAÇÃO (PR) - Melhor K: {best_k}\")\n",
    "    print(\"-\"*60)\n",
    "\n",
    "    #Métricas para a análise com base nos dados preditos pelo modelo e valores reais do test\n",
    "    print(classification_report(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d8260b",
   "metadata": {},
   "source": [
    "Pyplots sobre os dados preditos e reais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e185f2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=============== Analise dos resultados da semente seed1: 19 ===============\n",
      "        TP   FP   FN     TN  Precision  Recall  F1-Score  Support\n",
      "P_1_1  8.0  1.0  0.0  148.0      0.889   1.000     0.941      8.0\n",
      "P_1_2  9.0  0.0  0.0  148.0      1.000   1.000     1.000      9.0\n",
      "P_1_3  9.0  0.0  0.0  148.0      1.000   1.000     1.000      9.0\n",
      "P_2_1  9.0  0.0  0.0  148.0      1.000   1.000     1.000      9.0\n",
      "P_2_2  8.0  3.0  0.0  146.0      0.727   1.000     0.842      8.0\n",
      "P_2_3  8.0  1.0  1.0  147.0      0.889   0.889     0.889      9.0\n",
      "P_3_1  3.0  0.0  2.0  152.0      1.000   0.600     0.750      5.0\n",
      "P_3_2  5.0  3.0  0.0  149.0      0.625   1.000     0.769      5.0\n",
      "P_3_3  5.0  0.0  0.0  152.0      1.000   1.000     1.000      5.0\n",
      "P_4_1  4.0  1.0  1.0  151.0      0.800   0.800     0.800      5.0\n",
      "P_4_2  2.0  1.0  3.0  151.0      0.667   0.400     0.500      5.0\n",
      "P_4_3  3.0  0.0  2.0  152.0      1.000   0.600     0.750      5.0\n",
      "P_5_1  2.0  0.0  3.0  152.0      1.000   0.400     0.571      5.0\n",
      "P_5_2  5.0  2.0  0.0  150.0      0.714   1.000     0.833      5.0\n",
      "P_5_3  2.0  1.0  3.0  151.0      0.667   0.400     0.500      5.0\n",
      "P_6_1  4.0  2.0  1.0  150.0      0.667   0.800     0.727      5.0\n",
      "P_6_2  1.0  1.0  4.0  151.0      0.500   0.200     0.286      5.0\n",
      "P_6_3  5.0  2.0  0.0  150.0      0.714   1.000     0.833      5.0\n",
      "P_7_1  3.0  1.0  2.0  151.0      0.750   0.600     0.667      5.0\n",
      "P_7_2  5.0  1.0  0.0  151.0      0.833   1.000     0.909      5.0\n",
      "P_7_3  4.0  2.0  1.0  150.0      0.667   0.800     0.727      5.0\n",
      "P_8_1  2.0  0.0  3.0  152.0      1.000   0.400     0.571      5.0\n",
      "P_8_2  3.0  1.0  2.0  151.0      0.750   0.600     0.667      5.0\n",
      "P_8_3  4.0  3.0  1.0  149.0      0.571   0.800     0.667      5.0\n",
      "P_9_1  4.0  4.0  1.0  148.0      0.500   0.800     0.615      5.0\n",
      "P_9_2  5.0  0.0  0.0  152.0      1.000   1.000     1.000      5.0\n",
      "P_9_3  3.0  2.0  2.0  150.0      0.600   0.600     0.600      5.0\n",
      "\n",
      "=============== Analise dos resultados da semente seed2: 47 ===============\n",
      "        TP   FP   FN     TN  Precision  Recall  F1-Score  Support\n",
      "P_1_1  8.0  0.0  0.0  149.0      1.000   1.000     1.000      8.0\n",
      "P_1_2  9.0  0.0  0.0  148.0      1.000   1.000     1.000      9.0\n",
      "P_1_3  9.0  0.0  0.0  148.0      1.000   1.000     1.000      9.0\n",
      "P_2_1  9.0  0.0  0.0  148.0      1.000   1.000     1.000      9.0\n",
      "P_2_2  8.0  1.0  0.0  148.0      0.889   1.000     0.941      8.0\n",
      "P_2_3  7.0  2.0  2.0  146.0      0.778   0.778     0.778      9.0\n",
      "P_3_1  3.0  0.0  2.0  152.0      1.000   0.600     0.750      5.0\n",
      "P_3_2  4.0  5.0  1.0  147.0      0.444   0.800     0.571      5.0\n",
      "P_3_3  5.0  0.0  0.0  152.0      1.000   1.000     1.000      5.0\n",
      "P_4_1  3.0  2.0  2.0  150.0      0.600   0.600     0.600      5.0\n",
      "P_4_2  1.0  1.0  4.0  151.0      0.500   0.200     0.286      5.0\n",
      "P_4_3  3.0  1.0  2.0  151.0      0.750   0.600     0.667      5.0\n",
      "P_5_1  3.0  1.0  2.0  151.0      0.750   0.600     0.667      5.0\n",
      "P_5_2  5.0  2.0  0.0  150.0      0.714   1.000     0.833      5.0\n",
      "P_5_3  2.0  3.0  3.0  149.0      0.400   0.400     0.400      5.0\n",
      "P_6_1  3.0  0.0  2.0  152.0      1.000   0.600     0.750      5.0\n",
      "P_6_2  3.0  1.0  2.0  151.0      0.750   0.600     0.667      5.0\n",
      "P_6_3  4.0  0.0  1.0  152.0      1.000   0.800     0.889      5.0\n",
      "P_7_1  5.0  2.0  0.0  150.0      0.714   1.000     0.833      5.0\n",
      "P_7_2  5.0  0.0  0.0  152.0      1.000   1.000     1.000      5.0\n",
      "P_7_3  4.0  2.0  1.0  150.0      0.667   0.800     0.727      5.0\n",
      "P_8_1  4.0  1.0  1.0  151.0      0.800   0.800     0.800      5.0\n",
      "P_8_2  5.0  4.0  0.0  148.0      0.556   1.000     0.714      5.0\n",
      "P_8_3  2.0  1.0  3.0  151.0      0.667   0.400     0.500      5.0\n",
      "P_9_1  0.0  1.0  5.0  151.0      0.000   0.000     0.000      5.0\n",
      "P_9_2  5.0  0.0  0.0  152.0      1.000   1.000     1.000      5.0\n",
      "P_9_3  5.0  3.0  0.0  149.0      0.625   1.000     0.769      5.0\n",
      "\n",
      "=============== Analise dos resultados da semente seed3: 45 ===============\n",
      "        TP   FP   FN     TN  Precision  Recall  F1-Score  Support\n",
      "P_1_1  9.0  0.0  0.0  148.0      1.000   1.000     1.000      9.0\n",
      "P_1_2  9.0  0.0  0.0  148.0      1.000   1.000     1.000      9.0\n",
      "P_1_3  9.0  0.0  0.0  148.0      1.000   1.000     1.000      9.0\n",
      "P_2_1  8.0  0.0  0.0  149.0      1.000   1.000     1.000      8.0\n",
      "P_2_2  8.0  0.0  0.0  149.0      1.000   1.000     1.000      8.0\n",
      "P_2_3  8.0  2.0  1.0  146.0      0.800   0.889     0.842      9.0\n",
      "P_3_1  2.0  0.0  3.0  152.0      1.000   0.400     0.571      5.0\n",
      "P_3_2  4.0  3.0  1.0  149.0      0.571   0.800     0.667      5.0\n",
      "P_3_3  5.0  0.0  0.0  152.0      1.000   1.000     1.000      5.0\n",
      "P_4_1  4.0  0.0  1.0  152.0      1.000   0.800     0.889      5.0\n",
      "P_4_2  5.0  2.0  0.0  150.0      0.714   1.000     0.833      5.0\n",
      "P_4_3  3.0  2.0  2.0  150.0      0.600   0.600     0.600      5.0\n",
      "P_5_1  3.0  2.0  2.0  150.0      0.600   0.600     0.600      5.0\n",
      "P_5_2  3.0  3.0  2.0  149.0      0.500   0.600     0.545      5.0\n",
      "P_5_3  2.0  4.0  3.0  148.0      0.333   0.400     0.364      5.0\n",
      "P_6_1  2.0  2.0  3.0  150.0      0.500   0.400     0.444      5.0\n",
      "P_6_2  3.0  0.0  2.0  152.0      1.000   0.600     0.750      5.0\n",
      "P_6_3  4.0  0.0  1.0  152.0      1.000   0.800     0.889      5.0\n",
      "P_7_1  3.0  0.0  2.0  152.0      1.000   0.600     0.750      5.0\n",
      "P_7_2  5.0  0.0  0.0  152.0      1.000   1.000     1.000      5.0\n",
      "P_7_3  5.0  3.0  0.0  149.0      0.625   1.000     0.769      5.0\n",
      "P_8_1  2.0  0.0  3.0  152.0      1.000   0.400     0.571      5.0\n",
      "P_8_2  4.0  2.0  1.0  150.0      0.667   0.800     0.727      5.0\n",
      "P_8_3  4.0  1.0  1.0  151.0      0.800   0.800     0.800      5.0\n",
      "P_9_1  3.0  5.0  2.0  147.0      0.375   0.600     0.462      5.0\n",
      "P_9_2  5.0  0.0  0.0  152.0      1.000   1.000     1.000      5.0\n",
      "P_9_3  4.0  0.0  1.0  152.0      1.000   0.800     0.889      5.0\n",
      "\n",
      "=============== Analise dos resultados da semente seed4: 83 ===============\n",
      "        TP   FP   FN     TN  Precision  Recall  F1-Score  Support\n",
      "P_1_1  9.0  0.0  0.0  148.0      1.000   1.000     1.000      9.0\n",
      "P_1_2  7.0  1.0  1.0  148.0      0.875   0.875     0.875      8.0\n",
      "P_1_3  9.0  2.0  0.0  146.0      0.818   1.000     0.900      9.0\n",
      "P_2_1  9.0  0.0  0.0  148.0      1.000   1.000     1.000      9.0\n",
      "P_2_2  9.0  1.0  0.0  147.0      0.900   1.000     0.947      9.0\n",
      "P_2_3  8.0  0.0  0.0  149.0      1.000   1.000     1.000      8.0\n",
      "P_3_1  4.0  1.0  1.0  151.0      0.800   0.800     0.800      5.0\n",
      "P_3_2  3.0  1.0  2.0  151.0      0.750   0.600     0.667      5.0\n",
      "P_3_3  5.0  1.0  0.0  151.0      0.833   1.000     0.909      5.0\n",
      "P_4_1  4.0  2.0  1.0  150.0      0.667   0.800     0.727      5.0\n",
      "P_4_2  3.0  0.0  2.0  152.0      1.000   0.600     0.750      5.0\n",
      "P_4_3  4.0  2.0  1.0  150.0      0.667   0.800     0.727      5.0\n",
      "P_5_1  1.0  1.0  4.0  151.0      0.500   0.200     0.286      5.0\n",
      "P_5_2  5.0  1.0  0.0  151.0      0.833   1.000     0.909      5.0\n",
      "P_5_3  3.0  3.0  2.0  149.0      0.500   0.600     0.545      5.0\n",
      "P_6_1  3.0  2.0  2.0  150.0      0.600   0.600     0.600      5.0\n",
      "P_6_2  3.0  2.0  2.0  150.0      0.600   0.600     0.600      5.0\n",
      "P_6_3  3.0  1.0  2.0  151.0      0.750   0.600     0.667      5.0\n",
      "P_7_1  4.0  0.0  1.0  152.0      1.000   0.800     0.889      5.0\n",
      "P_7_2  5.0  0.0  0.0  152.0      1.000   1.000     1.000      5.0\n",
      "P_7_3  2.0  4.0  3.0  148.0      0.333   0.400     0.364      5.0\n",
      "P_8_1  4.0  1.0  1.0  151.0      0.800   0.800     0.800      5.0\n",
      "P_8_2  5.0  3.0  0.0  149.0      0.625   1.000     0.769      5.0\n",
      "P_8_3  2.0  1.0  3.0  151.0      0.667   0.400     0.500      5.0\n",
      "P_9_1  2.0  3.0  3.0  149.0      0.400   0.400     0.400      5.0\n",
      "P_9_2  4.0  0.0  1.0  152.0      1.000   0.800     0.889      5.0\n",
      "P_9_3  3.0  1.0  2.0  151.0      0.750   0.600     0.667      5.0\n",
      "\n",
      "=============== Analise dos resultados da semente seed5: 69 ===============\n",
      "        TP   FP   FN     TN  Precision  Recall  F1-Score  Support\n",
      "P_1_1  9.0  1.0  0.0  147.0      0.900   1.000     0.947      9.0\n",
      "P_1_2  8.0  0.0  1.0  148.0      1.000   0.889     0.941      9.0\n",
      "P_1_3  9.0  2.0  0.0  146.0      0.818   1.000     0.900      9.0\n",
      "P_2_1  8.0  0.0  0.0  149.0      1.000   1.000     1.000      8.0\n",
      "P_2_2  7.0  0.0  1.0  149.0      1.000   0.875     0.933      8.0\n",
      "P_2_3  9.0  2.0  0.0  146.0      0.818   1.000     0.900      9.0\n",
      "P_3_1  1.0  1.0  4.0  151.0      0.500   0.200     0.286      5.0\n",
      "P_3_2  3.0  5.0  2.0  147.0      0.375   0.600     0.462      5.0\n",
      "P_3_3  3.0  0.0  2.0  152.0      1.000   0.600     0.750      5.0\n",
      "P_4_1  4.0  2.0  1.0  150.0      0.667   0.800     0.727      5.0\n",
      "P_4_2  2.0  1.0  3.0  151.0      0.667   0.400     0.500      5.0\n",
      "P_4_3  3.0  4.0  2.0  148.0      0.429   0.600     0.500      5.0\n",
      "P_5_1  3.0  3.0  2.0  149.0      0.500   0.600     0.545      5.0\n",
      "P_5_2  5.0  1.0  0.0  151.0      0.833   1.000     0.909      5.0\n",
      "P_5_3  1.0  0.0  4.0  152.0      1.000   0.200     0.333      5.0\n",
      "P_6_1  3.0  0.0  2.0  152.0      1.000   0.600     0.750      5.0\n",
      "P_6_2  3.0  0.0  2.0  152.0      1.000   0.600     0.750      5.0\n",
      "P_6_3  5.0  1.0  0.0  151.0      0.833   1.000     0.909      5.0\n",
      "P_7_1  4.0  1.0  1.0  151.0      0.800   0.800     0.800      5.0\n",
      "P_7_2  5.0  2.0  0.0  150.0      0.714   1.000     0.833      5.0\n",
      "P_7_3  5.0  1.0  0.0  151.0      0.833   1.000     0.909      5.0\n",
      "P_8_1  3.0  1.0  2.0  151.0      0.750   0.600     0.667      5.0\n",
      "P_8_2  5.0  3.0  0.0  149.0      0.625   1.000     0.769      5.0\n",
      "P_8_3  4.0  1.0  1.0  151.0      0.800   0.800     0.800      5.0\n",
      "P_9_1  1.0  3.0  4.0  149.0      0.250   0.200     0.222      5.0\n",
      "P_9_2  5.0  0.0  0.0  152.0      1.000   1.000     1.000      5.0\n",
      "P_9_3  4.0  0.0  1.0  152.0      1.000   0.800     0.889      5.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for seed, valores in set_test_pred_categories.items():\n",
    "\n",
    "    print(f\"\\n=============== Analise dos resultados da semente {seed}: {valores['seed']} ===============\")\n",
    "    y_true = valores['values_test']\n",
    "    y_pred = valores['values_pred']\n",
    "\n",
    "    labels = np.unique(y_true)\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    # Cria dicionário para armazenar as métricas individuais\n",
    "    metrics_individuais = {}\n",
    "\n",
    "    for i, label in enumerate(labels):\n",
    "        TP = cm[i, i]\n",
    "        FP = cm[:, i].sum() - TP\n",
    "        FN = cm[i, :].sum() - TP\n",
    "        TN = cm.sum() - (TP + FP + FN)\n",
    "        \n",
    "        Precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "        Recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "        F1 = (2 * Precision * Recall) / (Precision + Recall) if (Precision + Recall) > 0 else 0\n",
    "        Support = cm[i, :].sum()\n",
    "        \n",
    "        metrics_individuais[label] = {\n",
    "            'TP': TP, 'FP': FP, 'FN': FN, 'TN': TN,\n",
    "            'Precision': round(Precision, 3),\n",
    "            'Recall': round(Recall, 3),\n",
    "            'F1-Score': round(F1, 3),\n",
    "            'Support': Support\n",
    "        }\n",
    "\n",
    "    # Converte em DataFrame para visualização\n",
    "    df_metrics = pd.DataFrame(metrics_individuais).T\n",
    "    df_metrics = df_metrics.sort_index()\n",
    "    print(df_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7640246f",
   "metadata": {},
   "source": [
    "Fazer analise das métricas para outros dispositivos\n",
    "Fazer analise de como a direção do celular influencia na predição -> hipotese cair abaixo 50%\n",
    "\n",
    "- Treinamento com dados da direção 'norte'e teste com os dados da direção 'leste'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
